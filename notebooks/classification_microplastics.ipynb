{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Microplastics Classification Method Comparison\n",
        "\n",
        "**Comparing 3 Deep Learning Classification Methods**\n",
        "\n",
        "This notebook trains and compares 3 different classification architectures for identifying microplastic particle types.\n",
        "\n",
        "## Task: Multi-class Classification\n",
        "- **Input**: RGB images of microplastic particles\n",
        "- **Output**: Class label (Fragment, Bead, Fiber)\n",
        "- **Dataset**: micro-plastics-sem from datasets_subset_Exp2\n",
        "- **Framework**: PyTorch with transfer learning\n",
        "\n",
        "## Classification Methods Compared\n",
        "\n",
        "### 1. **ResNet50** (Residual Networks)\n",
        "- Deep architecture (50 layers) with skip connections\n",
        "- Pre-trained on ImageNet → transfer learning\n",
        "- Strong baseline for image classification\n",
        "- Good at capturing complex features\n",
        "\n",
        "### 2. **EfficientNet-B0** (Efficient Architecture)\n",
        "- Optimized compound scaling of depth, width, resolution\n",
        "- Fewer parameters, faster inference\n",
        "- State-of-the-art efficiency\n",
        "- Better accuracy-to-parameter ratio\n",
        "\n",
        "### 3. **MobileNetV2** (Lightweight Mobile Architecture)\n",
        "- Designed for mobile/edge devices\n",
        "- Inverted residual blocks with linear bottlenecks\n",
        "- Very fast inference, small model size\n",
        "- Great for deployment scenarios\n",
        "\n",
        "## Classification Categories\n",
        "\n",
        "- **Fragment**: Irregular hard plastic pieces\n",
        "- **Bead**: Spherical plastic pellets\n",
        "- **Fiber**: Thread-like plastic strands\n",
        "\n",
        "## Setup Instructions for Kaggle\n",
        "\n",
        "1. Upload `micro-plastics-sem` dataset to Kaggle\n",
        "2. Enable GPU: Settings → Accelerator → GPU T4 x2\n",
        "3. Add dataset: + Add data → micro-plastics-sem\n",
        "4. Run all cells\n",
        "\n",
        "**Expected Runtime**: ~30-40 minutes on Kaggle GPU (20 epochs per model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages with compatible versions\n",
        "# IMPORTANT: Install in this specific order to avoid conflicts\n",
        "\n",
        "# Step 1: Uninstall problematic packages\n",
        "!pip uninstall -y numpy scipy -q\n",
        "\n",
        "# Step 2: Install NumPy 1.26.x (compatible with scipy and mkl packages)\n",
        "!pip install -q \"numpy==1.26.4\"\n",
        "\n",
        "# Step 3: Install scipy with the compatible NumPy\n",
        "!pip install -q \"scipy>=1.11.0,<2.0.0\"\n",
        "\n",
        "# Step 4: Install other packages\n",
        "!pip install -q albumentations opencv-python-headless scikit-learn matplotlib seaborn tqdm pandas timm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from collections import Counter, defaultdict\n",
        "import timm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'CUDA version: {torch.version.cuda}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')\n",
        "\n",
        "print(f'\\nPyTorch version: {torch.__version__}')\n",
        "print(f'NumPy version: {np.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Configuration\n",
        "\n",
        "The dataset should be organized with class folders:\n",
        "```\n",
        "/kaggle/input/micro-plastics-sem/Microplastics_SEM/dataset1/dataset1/datasets_subset_Exp2/\n",
        "├── bead/\n",
        "│   ├── img001.jpg\n",
        "│   └── ...\n",
        "├── fragment/\n",
        "└── fibre_1/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset configuration\n",
        "print(\"Searching for dataset...\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Define class names (matching folder names in datasets_subset_Exp2)\n",
        "CLASS_NAMES = ['bead', 'fragment', 'fibre_1']  # Will map fibre_1 to 'fiber' for display\n",
        "DISPLAY_NAMES = ['Bead', 'Fragment', 'Fiber']  # User-friendly names\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "# Auto-detect dataset path\n",
        "DATASET_PATH = None\n",
        "\n",
        "# Check Kaggle paths\n",
        "if os.path.exists('/kaggle/input/'):\n",
        "    print(\"Running on Kaggle\")\n",
        "    \n",
        "    # Try common paths\n",
        "    possible_paths = [\n",
        "        '/kaggle/input/microplastics-sem-dataset/Microplastics_SEM/dataset1/dataset1/datasets_subset_Exp2'\n",
        "    ]\n",
        "    \n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            DATASET_PATH = path\n",
        "            print(f\"Found dataset at: {DATASET_PATH}\")\n",
        "            break\n",
        "    \n",
        "    if not DATASET_PATH:\n",
        "        # List available datasets\n",
        "        available = os.listdir('/kaggle/input/')\n",
        "        print(f\"\\nAvailable datasets:\")\n",
        "        for ds in available:\n",
        "            print(f\"  - {ds}\")\n",
        "else:\n",
        "    # Local path\n",
        "    local_path = r\"C:\\Users\\SHIVAPREETHAM ROHITH\\Desktop\\AI\\micro-plastic-detection\\data\\Microplastics_SEM\\dataset1\\dataset1\\datasets_subset_Exp2\"\n",
        "    if os.path.exists(local_path):\n",
        "        DATASET_PATH = local_path\n",
        "        print(f\"Using local dataset: {DATASET_PATH}\")\n",
        "\n",
        "# Create output directories\n",
        "output_dir = '/kaggle/working/' if os.path.exists('/kaggle/working/') else './output/'\n",
        "os.makedirs(os.path.join(output_dir, 'models'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'results'), exist_ok=True)\n",
        "\n",
        "# Verify dataset structure\n",
        "if DATASET_PATH:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DATASET STRUCTURE\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    class_counts = {}\n",
        "    for class_name in CLASS_NAMES:\n",
        "        class_path = os.path.join(DATASET_PATH, class_name)\n",
        "        if os.path.exists(class_path):\n",
        "            images = []\n",
        "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.JPG', '*.JPEG', '*.PNG', '*.TIF']:\n",
        "                images.extend(glob.glob(os.path.join(class_path, ext)))\n",
        "            class_counts[class_name] = len(images)\n",
        "            display_name = DISPLAY_NAMES[CLASS_NAMES.index(class_name)]\n",
        "            print(f\"  {display_name:12s}: {len(images):5d} images\")\n",
        "        else:\n",
        "            class_counts[class_name] = 0\n",
        "            print(f\"  {class_name:12s}: NOT FOUND\")\n",
        "    \n",
        "    total_images = sum(class_counts.values())\n",
        "    print(f\"\\n  Total images: {total_images}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    if total_images == 0:\n",
        "        print(\"\\n⚠️ WARNING: No images found in class folders!\")\n",
        "        print(f\"Path: {DATASET_PATH}\")\n",
        "        print(\"Please verify the dataset structure.\")\n",
        "        raise FileNotFoundError(\"No images found in dataset\")\n",
        "else:\n",
        "    print(\"\\n⚠️ WARNING: Dataset not found!\")\n",
        "    print(\"Please add 'microplastics-sem-dataset' dataset in Kaggle:\")\n",
        "    print(\"  + Add data → microplastics-sem-dataset\")\n",
        "    raise FileNotFoundError(\"Dataset not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dataset Class and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MicroplasticsClassificationDataset(Dataset):\n",
        "    \"\"\"Dataset for microplastics classification\"\"\"\n",
        "    \n",
        "    def __init__(self, data_dir, class_names, transform=None, image_size=(224, 224)):\n",
        "        self.data_dir = data_dir\n",
        "        self.class_names = class_names\n",
        "        self.transform = transform\n",
        "        self.image_size = image_size\n",
        "        \n",
        "        # Build file list\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        \n",
        "        for class_idx, class_name in enumerate(class_names):\n",
        "            class_dir = os.path.join(data_dir, class_name)\n",
        "            if os.path.exists(class_dir):\n",
        "                for ext in ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.JPG', '*.JPEG', '*.PNG', '*.TIF']:\n",
        "                    files = glob.glob(os.path.join(class_dir, ext))\n",
        "                    self.images.extend(files)\n",
        "                    self.labels.extend([class_idx] * len(files))\n",
        "        \n",
        "        print(f\"Loaded {len(self.images)} images from {data_dir}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        # Load image\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Failed to load image: {img_path}\")\n",
        "        \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, self.image_size)\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Data augmentation for training\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=90, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "    A.OneOf([\n",
        "        A.MotionBlur(blur_limit=5, p=1.0),\n",
        "        A.MedianBlur(blur_limit=5, p=1.0),\n",
        "        A.GaussianBlur(blur_limit=5, p=1.0),\n",
        "    ], p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=45, p=0.5),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Create dataset\n",
        "if DATASET_PATH:\n",
        "    print(\"\\nCreating dataset...\")\n",
        "    full_dataset = MicroplasticsClassificationDataset(\n",
        "        DATASET_PATH,\n",
        "        CLASS_NAMES,\n",
        "        transform=train_transform,\n",
        "        image_size=(224, 224)\n",
        "    )\n",
        "    \n",
        "    # Split dataset: 70% train, 20% val, 10% test\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = int(0.2 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size - val_size\n",
        "    \n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        full_dataset,\n",
        "        [train_size, val_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42)\n",
        "    )\n",
        "    \n",
        "    # Apply validation transform to val and test\n",
        "    val_dataset.dataset.transform = val_transform\n",
        "    test_dataset.dataset.transform = val_transform\n",
        "    \n",
        "    print(f\"\\nDataset split:\")\n",
        "    print(f\"  Train: {len(train_dataset)} ({len(train_dataset)/len(full_dataset)*100:.1f}%)\")\n",
        "    print(f\"  Val:   {len(val_dataset)} ({len(val_dataset)/len(full_dataset)*100:.1f}%)\")\n",
        "    print(f\"  Test:  {len(test_dataset)} ({len(test_dataset)/len(full_dataset)*100:.1f}%)\")\n",
        "    \n",
        "    # Create data loaders\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_WORKERS = 2\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    \n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    \n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nData loaders created:\")\n",
        "    print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "    print(f\"  Train batches: {len(train_loader)}\")\n",
        "    print(f\"  Val batches:   {len(val_loader)}\")\n",
        "    print(f\"  Test batches:  {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualize Sample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_samples(dataloader, class_names, num_samples=8):\n",
        "    \"\"\"Visualize sample images from each class\"\"\"\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    data_iter = iter(dataloader)\n",
        "    images, labels = next(data_iter)\n",
        "    \n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        # Denormalize image\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        label = labels[i].item()\n",
        "        class_name = class_names[label]\n",
        "        \n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'Class: {class_name}', fontsize=14, fontweight='bold')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    save_path = os.path.join(output_dir, 'results', 'sample_images.png')\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # Show class distribution\n",
        "    label_counts = Counter(labels.numpy())\n",
        "    print(f\"\\nClass distribution in batch:\")\n",
        "    for class_idx, count in sorted(label_counts.items()):\n",
        "        print(f\"  {class_names[class_idx]:12s}: {count} samples\")\n",
        "\n",
        "if DATASET_PATH:\n",
        "    print(\"Visualizing sample data...\")\n",
        "    visualize_samples(train_loader, CLASS_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Architectures\n",
        "\n",
        "We'll compare 3 classification architectures:\n",
        "1. **ResNet50** (50 layers, strong baseline)\n",
        "2. **EfficientNet-B0** (efficient scaling, best accuracy/params)\n",
        "3. **MobileNetV2** (lightweight, fast inference)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_models(num_classes=3):\n",
        "    \"\"\"Create all 3 classification models\"\"\"\n",
        "    models_dict = {}\n",
        "    \n",
        "    # Model 1: ResNet50\n",
        "    resnet50 = models.resnet50(pretrained=True)\n",
        "    num_features = resnet50.fc.in_features\n",
        "    resnet50.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(num_features, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    models_dict['ResNet50'] = resnet50\n",
        "    \n",
        "    # Model 2: EfficientNet-B0\n",
        "    efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n",
        "    num_features = efficientnet.classifier.in_features\n",
        "    efficientnet.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(256, num_classes)\n",
        "    )\n",
        "    models_dict['EfficientNet-B0'] = efficientnet\n",
        "    \n",
        "    # Model 3: MobileNetV2\n",
        "    mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "    num_features = mobilenet.classifier[1].in_features\n",
        "    mobilenet.classifier = nn.Sequential(\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(num_features, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(256, num_classes)\n",
        "    )\n",
        "    models_dict['MobileNetV2'] = mobilenet\n",
        "    \n",
        "    return models_dict\n",
        "\n",
        "print(\"Creating models...\")\n",
        "all_models = create_models(NUM_CLASSES)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL ARCHITECTURES\")\n",
        "print(\"=\"*70)\n",
        "for name, model in all_models.items():\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"{name:20s}: {total_params:>12,} params ({trainable_params:>12,} trainable)\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_model(model_name, model, train_loader, val_loader, num_epochs=20, lr=1e-4):\n",
        "    \"\"\"\n",
        "    Train a single classification model\n",
        "    \n",
        "    Args:\n",
        "        model_name: Name of the model\n",
        "        model: PyTorch model\n",
        "        train_loader: Training data loader\n",
        "        val_loader: Validation data loader\n",
        "        num_epochs: Number of training epochs\n",
        "        lr: Learning rate\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with training history and metrics\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3, verbose=False\n",
        "    )\n",
        "    \n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_acc': [],\n",
        "        'val_precision': [],\n",
        "        'val_recall': [],\n",
        "        'val_f1': [],\n",
        "    }\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    best_epoch = 0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_preds = []\n",
        "        train_labels = []\n",
        "        \n",
        "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n",
        "        for images, labels in train_bar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            train_preds.extend(preds.cpu().numpy())\n",
        "            train_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            train_bar.set_postfix({'loss': loss.item()})\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        train_acc = accuracy_score(train_labels, train_preds)\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]  \", leave=False)\n",
        "            for images, labels in val_bar:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                \n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                \n",
        "                val_bar.set_postfix({'loss': loss.item()})\n",
        "        \n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_prec = precision_score(val_labels, val_preds, average='weighted', zero_division=0)\n",
        "        val_rec = recall_score(val_labels, val_preds, average='weighted', zero_division=0)\n",
        "        val_f1 = f1_score(val_labels, val_preds, average='weighted', zero_division=0)\n",
        "        \n",
        "        # Update learning rate\n",
        "        scheduler.step(val_acc)\n",
        "        \n",
        "        # Save history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_precision'].append(val_prec)\n",
        "        history['val_recall'].append(val_rec)\n",
        "        history['val_f1'].append(val_f1)\n",
        "        \n",
        "        # Print progress\n",
        "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "            print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "                  f\"Loss: {train_loss:.4f}/{val_loss:.4f} | \"\n",
        "                  f\"Acc: {train_acc:.4f}/{val_acc:.4f} | \"\n",
        "                  f\"F1: {val_f1:.4f}\")\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_epoch = epoch + 1\n",
        "            model_path = os.path.join(output_dir, 'models', f'{model_name.lower().replace(\"-\", \"_\")}_best.pth')\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"\\n✓ {model_name} training complete!\")\n",
        "    print(f\"  Best Val Acc: {best_val_acc:.4f} (epoch {best_epoch})\")\n",
        "    print(f\"  Training time: {training_time/60:.1f} minutes\")\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'history': history,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'best_epoch': best_epoch,\n",
        "        'training_time': training_time\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TRAINING CLASSIFICATION MODELS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Dataset: {DATASET_PATH}\")\n",
        "print(f\"Classes: {NUM_CLASSES} ({', '.join(DISPLAY_NAMES)})\")\n",
        "print(f\"Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Device: {device}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Train each model\n",
        "results = {}\n",
        "for model_name, model in all_models.items():\n",
        "    results[model_name] = train_one_model(\n",
        "        model_name, model, train_loader, val_loader,\n",
        "        num_epochs=NUM_EPOCHS, lr=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL MODELS TRAINED\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Comparison Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "comparison_data = []\n",
        "for model_name, result in results.items():\n",
        "    model = result['model']\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    \n",
        "    comparison_data.append({\n",
        "        'Model': model_name,\n",
        "        'Best Val Acc': f\"{result['best_val_acc']:.4f}\",\n",
        "        'Best Epoch': result['best_epoch'],\n",
        "        'Final Val Acc': f\"{result['history']['val_acc'][-1]:.4f}\",\n",
        "        'Final Val F1': f\"{result['history']['val_f1'][-1]:.4f}\",\n",
        "        'Parameters (M)': f\"{total_params/1e6:.2f}\",\n",
        "        'Training Time (min)': f\"{result['training_time']/60:.1f}\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values('Best Val Acc', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save comparison table\n",
        "comparison_df.to_csv(os.path.join(output_dir, 'results', 'classification_comparison.csv'), index=False)\n",
        "print(\"\\nComparison table saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training Curves Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves for all models\n",
        "fig, axes = plt.subplots(2, 3, figsize=(22, 12))\n",
        "\n",
        "colors = {'ResNet50': '#E74C3C', 'EfficientNet-B0': '#3498DB', 'MobileNetV2': '#2ECC71'}\n",
        "metrics = [\n",
        "    ('train_loss', 'Training Loss', axes[0, 0]),\n",
        "    ('val_loss', 'Validation Loss', axes[0, 1]),\n",
        "    ('val_acc', 'Validation Accuracy', axes[0, 2]),\n",
        "    ('val_precision', 'Validation Precision', axes[1, 0]),\n",
        "    ('val_recall', 'Validation Recall', axes[1, 1]),\n",
        "    ('val_f1', 'Validation F1 Score', axes[1, 2]),\n",
        "]\n",
        "\n",
        "for metric_key, title, ax in metrics:\n",
        "    for model_name, result in results.items():\n",
        "        values = result['history'][metric_key]\n",
        "        ax.plot(range(1, len(values)+1), values,\n",
        "               label=model_name, linewidth=2.5, color=colors[model_name])\n",
        "    \n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Epoch', fontsize=11)\n",
        "    ax.set_ylabel(title.split()[-1], fontsize=11)\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3, linestyle='--')\n",
        "\n",
        "plt.suptitle('Microplastics Classification - Training Comparison',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'results', 'training_curves_comparison.png'),\n",
        "           dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Training curves saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Test Set Evaluation (Best Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find best model\n",
        "best_model_name = max(results.items(), key=lambda x: x[1]['best_val_acc'])[0]\n",
        "best_model = results[best_model_name]['model']\n",
        "\n",
        "print(f\"\\nBest model: {best_model_name}\")\n",
        "print(f\"Best validation accuracy: {results[best_model_name]['best_val_acc']:.4f}\")\n",
        "\n",
        "# Load best checkpoint\n",
        "checkpoint_path = os.path.join(output_dir, 'models', f'{best_model_name.lower().replace(\"-\", \"_\")}_best.pth')\n",
        "best_model.load_state_dict(torch.load(checkpoint_path))\n",
        "best_model.eval()\n",
        "\n",
        "# Evaluate on test set\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss = 0.0\n",
        "test_preds = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = best_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        test_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_preds.extend(preds.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "test_prec = precision_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
        "test_rec = recall_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
        "test_f1 = f1_score(test_labels, test_preds, average='weighted', zero_division=0)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"TEST SET RESULTS - {best_model_name}\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Loss:      {test_loss:.4f}\")\n",
        "print(f\"Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"Precision: {test_prec:.4f}\")\n",
        "print(f\"Recall:    {test_rec:.4f}\")\n",
        "print(f\"F1 Score:  {test_f1:.4f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Per-class metrics\n",
        "print(\"\\nPer-Class Performance:\")\n",
        "print(\"-\" * 70)\n",
        "report = classification_report(test_labels, test_preds, target_names=DISPLAY_NAMES, digits=4)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "# Raw counts\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=DISPLAY_NAMES, yticklabels=DISPLAY_NAMES,\n",
        "            cbar_kws={'label': 'Count'}, annot_kws={'size': 14})\n",
        "axes[0].set_title(f'Confusion Matrix (Counts) - {best_model_name}',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted', fontsize=12)\n",
        "axes[0].set_ylabel('Actual', fontsize=12)\n",
        "\n",
        "# Normalized\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues', ax=axes[1],\n",
        "            xticklabels=DISPLAY_NAMES, yticklabels=DISPLAY_NAMES,\n",
        "            cbar_kws={'label': 'Proportion'}, annot_kws={'size': 14})\n",
        "axes[1].set_title(f'Confusion Matrix (Normalized) - {best_model_name}',\n",
        "                 fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted', fontsize=12)\n",
        "axes[1].set_ylabel('Actual', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'results', 'confusion_matrix.png'),\n",
        "           dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion matrix saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Visualize Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_predictions(model, dataloader, class_names, device, num_samples=12):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    data_iter = iter(dataloader)\n",
        "    images, labels = next(data_iter)\n",
        "    images_gpu = images.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(images_gpu)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        confidences, preds = torch.max(probs, 1)\n",
        "    \n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        # Denormalize\n",
        "        img = images[i].permute(1, 2, 0).numpy()\n",
        "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        true_label = labels[i].item()\n",
        "        pred_label = preds[i].item()\n",
        "        confidence = confidences[i].item()\n",
        "        \n",
        "        true_class = class_names[true_label]\n",
        "        pred_class = class_names[pred_label]\n",
        "        \n",
        "        # Plot\n",
        "        axes[i].imshow(img)\n",
        "        \n",
        "        # Color code: green for correct, red for incorrect\n",
        "        color = 'green' if true_label == pred_label else 'red'\n",
        "        \n",
        "        title = f'True: {true_class}\\nPred: {pred_class} ({confidence:.1%})'\n",
        "        axes[i].set_title(title, fontsize=12, fontweight='bold', color=color)\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Predictions - {best_model_name}', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'results', 'predictions.png'),\n",
        "               dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Generating prediction visualizations...\")\n",
        "visualize_predictions(best_model, test_loader, DISPLAY_NAMES, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Save Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive summary\n",
        "results_text = f\"\"\"Microplastics Classification Method Comparison\n",
        "================================================\n",
        "\n",
        "Dataset: {DATASET_PATH}\n",
        "Classes: {NUM_CLASSES} ({', '.join(DISPLAY_NAMES)})\n",
        "Total images: {len(full_dataset)}\n",
        "Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\n",
        "\n",
        "Training Configuration:\n",
        "----------------------\n",
        "Image size: 224x224\n",
        "Batch size: {BATCH_SIZE}\n",
        "Epochs: {NUM_EPOCHS}\n",
        "Learning rate: {LEARNING_RATE}\n",
        "Optimizer: Adam\n",
        "Loss function: CrossEntropyLoss\n",
        "\n",
        "Models Compared:\n",
        "---------------\n",
        "{comparison_df.to_string(index=False)}\n",
        "\n",
        "Best Model: {best_model_name}\n",
        "============================================\n",
        "\n",
        "Test Set Performance:\n",
        "--------------------\n",
        "Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)\n",
        "Precision: {test_prec:.4f}\n",
        "Recall:    {test_rec:.4f}\n",
        "F1 Score:  {test_f1:.4f}\n",
        "Loss:      {test_loss:.4f}\n",
        "\n",
        "Per-Class Performance:\n",
        "---------------------\n",
        "{classification_report(test_labels, test_preds, target_names=DISPLAY_NAMES, digits=4)}\n",
        "\n",
        "Confusion Matrix:\n",
        "----------------\n",
        "{cm}\n",
        "\n",
        "Generated Files:\n",
        "---------------\n",
        "Models:\n",
        "  - resnet50_best.pth\n",
        "  - efficientnet_b0_best.pth\n",
        "  - mobilenetv2_best.pth\n",
        "\n",
        "Visualizations:\n",
        "  - classification_comparison.csv\n",
        "  - training_curves_comparison.png\n",
        "  - confusion_matrix.png\n",
        "  - predictions.png\n",
        "  - sample_images.png\n",
        "  - results.txt (this file)\n",
        "\n",
        "Recommendation:\n",
        "--------------\n",
        "Best model for microplastic classification: {best_model_name}\n",
        "Accuracy: {results[best_model_name]['best_val_acc']:.4f}\n",
        "\n",
        "Model characteristics:\n",
        "- ResNet50: Strong baseline, good accuracy, more parameters\n",
        "- EfficientNet-B0: Best efficiency, balanced accuracy/speed\n",
        "- MobileNetV2: Fastest inference, good for deployment\n",
        "\n",
        "Choose based on your priorities:\n",
        "- Highest accuracy → ResNet50 or EfficientNet-B0\n",
        "- Fast inference/deployment → MobileNetV2\n",
        "- Best balance → EfficientNet-B0\n",
        "\"\"\"\n",
        "\n",
        "# Save results\n",
        "with open(os.path.join(output_dir, 'results', 'results.txt'), 'w') as f:\n",
        "    f.write(results_text)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ALL RESULTS SAVED\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"\\nFiles saved to: {os.path.join(output_dir, 'results')}\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What This Notebook Does:\n",
        "\n",
        "This notebook compares **3 deep learning classification methods** for identifying microplastic particle types (Bead, Fragment, Fiber). All models are trained on the same dataset splits with identical hyperparameters for fair comparison.\n",
        "\n",
        "### Methods Compared:\n",
        "\n",
        "1. **ResNet50** - Deep residual network (50 layers) with skip connections. Strong baseline, high accuracy.\n",
        "\n",
        "2. **EfficientNet-B0** - Compound scaling architecture. Best efficiency with competitive accuracy.\n",
        "\n",
        "3. **MobileNetV2** - Lightweight mobile architecture. Fast inference, good for deployment.\n",
        "\n",
        "### Key Features:\n",
        "\n",
        "- Transfer learning from ImageNet pre-trained weights\n",
        "- Data augmentation (flips, rotations, brightness, noise)\n",
        "- Cross-entropy loss with Adam optimizer\n",
        "- Learning rate scheduling\n",
        "- Comprehensive evaluation metrics (accuracy, precision, recall, F1)\n",
        "- Confusion matrix analysis\n",
        "- Visual predictions with confidence scores\n",
        "\n",
        "### Typical Results:\n",
        "\n",
        "- **Accuracy**: 85-95% depending on dataset quality\n",
        "- **Best model**: Usually EfficientNet-B0 or ResNet50\n",
        "- **MobileNetV2**: Slightly lower accuracy but 2-3x faster inference\n",
        "\n",
        "### How to Use Results:\n",
        "\n",
        "1. **Check comparison table** - Compare all models at a glance\n",
        "2. **Review training curves** - Ensure no overfitting\n",
        "3. **Analyze confusion matrix** - Identify which classes are confused\n",
        "4. **Examine per-class metrics** - Find weak points\n",
        "5. **Choose model** based on your priority (accuracy vs speed)\n",
        "\n",
        "### For Your Presentation:\n",
        "\n",
        "Include these visualizations:\n",
        "- Comparison table showing all 3 methods\n",
        "- Training curves (accuracy and F1 score)\n",
        "- Confusion matrix of best model\n",
        "- Sample predictions with confidence\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. Combine with segmentation for complete pipeline\n",
        "2. Try ensemble methods (combine predictions)\n",
        "3. Fine-tune best model with more epochs\n",
        "4. Deploy best model to web app or mobile\n",
        "5. Add more microplastic types if available\n",
        "\n",
        "### Inference Example:\n",
        "\n",
        "```python\n",
        "# Load best model\n",
        "model = all_models[best_model_name]\n",
        "model.load_state_dict(torch.load('resnet50_best.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Predict single image\n",
        "pred_class, confidence, probs = predict_single_image(\n",
        "    model, 'test_image.jpg', DISPLAY_NAMES, device\n",
        ")\n",
        "print(f\"Predicted: {pred_class} ({confidence:.1%} confidence)\")\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
