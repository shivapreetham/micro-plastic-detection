{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: U-Net Microplastic Segmentation - Kaggle Notebook\n",
    "\n",
    "**Complete pipeline for pixel-level microplastic segmentation**\n",
    "\n",
    "- **Task**: Binary segmentation (microplastic vs background)\n",
    "- **Model**: U-Net with Dice + BCE loss\n",
    "- **Dataset**: Microplastics SEM Dataset (Mendeley) - 237 SEM images with segmentation masks\n",
    "- **Framework**: PyTorch\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: Mendeley Data - Microplastics SEM Dataset\n",
    "- **Paper**: Automatic quantification and classification of microplastics in scanning electron micrographs\n",
    "- **Images**: 237 high-resolution SEM micrographs (50 Î¼m â€“ 1 mm particles)\n",
    "- **License**: CC BY 4.0\n",
    "\n",
    "## Setup Instructions for Kaggle\n",
    "1. Upload the `Microplastics_SEM` dataset folder to Kaggle Datasets\n",
    "2. In Kaggle notebook, click **\"+ Add data\"** â†’ Select your uploaded dataset\n",
    "3. The notebook will auto-detect the dataset structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q albumentations opencv-python-headless scikit-learn matplotlib seaborn tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from sklearn.metrics import jaccard_score, f1_score, precision_score, recall_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Setup\n",
    "\n",
    "**Instructions to use this notebook on Kaggle:**\n",
    "\n",
    "### Step 1: Upload Dataset to Kaggle\n",
    "1. Go to https://www.kaggle.com/datasets\n",
    "2. Click **\"New Dataset\"**\n",
    "3. Upload the **`micro-plastic-sem`** folder directly\n",
    "   - Path: `Microplastics_SEM/dataset1/dataset1/micro-plastic-sem/`\n",
    "   - Contains: `image/` and `label/` folders\n",
    "4. Set dataset name (e.g., `microplastics-sem`)\n",
    "5. Make it public or private\n",
    "6. Click **\"Create\"**\n",
    "\n",
    "### Step 2: Add Dataset to This Notebook\n",
    "1. In this Kaggle notebook, click **\"+ Add data\"** (right panel)\n",
    "2. Search for your dataset name\n",
    "3. Click **\"Add\"**\n",
    "\n",
    "### Expected Dataset Structure:\n",
    "```\n",
    "/kaggle/input/[your-dataset-name]/\n",
    "â”œâ”€â”€ image/    # 237 SEM images (.tif, .png, etc.)\n",
    "â””â”€â”€ label/    # 237 binary segmentation masks\n",
    "```\n",
    "\n",
    "**Note**: The notebook will automatically detect your dataset if it contains `image/` and `label/` folders. No manual path configuration needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# DATASET CONFIGURATION - MICROPLASTICS SEM DATASET\n# ============================================================\n\nimport os\nimport glob\n\nprint(\"Configuring Microplastics SEM dataset...\")\nprint(\"=\"*60)\n\n# List all available datasets in Kaggle input\navailable_datasets = []\nif os.path.exists('/kaggle/input/'):\n    available_datasets = os.listdir('/kaggle/input/')\n    print(f\"Available datasets in /kaggle/input/:\")\n    for ds in available_datasets:\n        print(f\"  - {ds}\")\nelse:\n    print(\"Not running on Kaggle - /kaggle/input/ not found\")\n    print(\"Checking local paths...\")\n\n# Initialize paths\nDATASET_PATH = None\nIMAGE_DIR = None\nMASK_DIR = None\n\n# Auto-detect Microplastics SEM dataset structure\nprint(\"\\nSearching for image and label folders...\")\n\nfor dataset_name in available_datasets:\n    base_path = f\"/kaggle/input/{dataset_name}\"\n    \n    # Check for direct image/label folders (uploaded micro-plastic-sem directly)\n    if os.path.exists(f\"{base_path}/image\") and os.path.exists(f\"{base_path}/label\"):\n        DATASET_PATH = base_path\n        IMAGE_DIR = f\"{base_path}/image\"\n        MASK_DIR = f\"{base_path}/label\"\n        print(f\"âœ“ Found dataset at root level: {dataset_name}\")\n        break\n    \n    # Check for nested structures\n    possible_paths = [\n        f\"{base_path}/micro-plastic-sem\",\n        f\"{base_path}/dataset1/micro-plastic-sem\",\n        f\"{base_path}/dataset1/dataset1/micro-plastic-sem\",\n        f\"{base_path}/Microplastics_SEM/dataset1/dataset1/micro-plastic-sem\",\n    ]\n    \n    for path in possible_paths:\n        if os.path.exists(path):\n            if os.path.exists(f\"{path}/image\") and os.path.exists(f\"{path}/label\"):\n                DATASET_PATH = path\n                IMAGE_DIR = f\"{path}/image\"\n                MASK_DIR = f\"{path}/label\"\n                print(f\"âœ“ Found dataset at: {path}\")\n                break\n    \n    if DATASET_PATH:\n        break\n\n# If not on Kaggle, check local path (for testing)\nif DATASET_PATH is None and not os.path.exists('/kaggle/input/'):\n    local_path = \"C:/Users/SHIVAPREETHAM ROHITH/Desktop/AI/micro-plastic-detection/data/Microplastics_SEM/dataset1/dataset1/micro-plastic-sem\"\n    if os.path.exists(local_path):\n        DATASET_PATH = local_path\n        IMAGE_DIR = f\"{local_path}/image\"\n        MASK_DIR = f\"{local_path}/label\"\n        print(f\"âœ“ Using local dataset path for testing\")\n\n# ============================================================\n# VERIFY AND DISPLAY DATASET INFORMATION\n# ============================================================\n\n# Create output directories\nif os.path.exists('/kaggle/working/'):\n    os.makedirs('/kaggle/working/models', exist_ok=True)\n    os.makedirs('/kaggle/working/results', exist_ok=True)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"DATASET CONFIGURATION\")\nprint(\"=\"*60)\n\nif DATASET_PATH is None or IMAGE_DIR is None or MASK_DIR is None:\n    print(\"\\nâš ï¸  ERROR: Could not auto-detect Microplastics SEM dataset!\")\n    print(\"\\nPlease ensure you have:\")\n    print(\"  1. Uploaded the micro-plastic-sem folder to Kaggle\")\n    print(\"  2. Added the dataset to this notebook (+ Add data button)\")\n    print(\"  3. Dataset contains 'image' and 'label' folders\")\n    print(\"\\nAvailable datasets:\", available_datasets)\n    print(\"\\nðŸ“ To manually set paths, add a new cell with:\")\n    print(\"   DATASET_PATH = '/kaggle/input/YOUR-DATASET-NAME'\")\n    print(\"   IMAGE_DIR = f'{DATASET_PATH}/image'\")\n    print(\"   MASK_DIR = f'{DATASET_PATH}/label'\")\nelse:\n    print(f\"\\nâœ“ Dataset path: {DATASET_PATH}\")\n    print(f\"âœ“ Image directory: {IMAGE_DIR}\")\n    print(f\"âœ“ Mask directory: {MASK_DIR}\")\n    print(f\"âœ“ Directories exist: {os.path.exists(IMAGE_DIR) and os.path.exists(MASK_DIR)}\")\n    \n    if os.path.exists(IMAGE_DIR) and os.path.exists(MASK_DIR):\n        # Count images and masks\n        image_files = []\n        mask_files = []\n        \n        for ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG', '*.png', '*.PNG', '*.tif', '*.tiff', '*.TIF', '*.TIFF']:\n            image_files.extend(glob.glob(os.path.join(IMAGE_DIR, ext)))\n            mask_files.extend(glob.glob(os.path.join(MASK_DIR, ext)))\n        \n        print(f\"\\nâœ“ Total images found: {len(image_files)}\")\n        print(f\"âœ“ Total masks found: {len(mask_files)}\")\n        \n        # Show sample files\n        if image_files:\n            print(f\"\\nSample images (first 5):\")\n            for img in sorted(image_files)[:5]:\n                print(f\"  - {os.path.basename(img)}\")\n        \n        if mask_files:\n            print(f\"\\nSample masks (first 5):\")\n            for msk in sorted(mask_files)[:5]:\n                print(f\"  - {os.path.basename(msk)}\")\n        \n        # Check if image and mask counts match\n        if len(image_files) == len(mask_files):\n            print(f\"\\nâœ“ Image and mask counts match!\")\n        else:\n            print(f\"\\nâš ï¸  Warning: Image count ({len(image_files)}) != Mask count ({len(mask_files)})\")\n        \n        # Display dataset info\n        print(\"\\n\" + \"=\"*60)\n        print(\"MICROPLASTICS SEM DATASET INFO\")\n        print(\"=\"*60)\n        print(\"Source: Mendeley Data\")\n        print(\"Paper: Automatic quantification and classification of microplastics\")\n        print(\"Imaging: Scanning Electron Microscopy (SEM)\")\n        print(\"Particle Size: 50 Î¼m â€“ 1 mm\")\n        print(\"Types: Fragments, Beads, Fibers\")\n        print(\"License: CC BY 4.0\")\n        print(\"=\"*60)\n        print(\"\\nðŸš€ Dataset configured successfully! Ready to train.\")\n    else:\n        print(f\"\\nâš ï¸  ERROR: Directories do not exist!\")\n        print(f\"  Image dir exists: {os.path.exists(IMAGE_DIR)}\")\n        print(f\"  Mask dir exists: {os.path.exists(MASK_DIR)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. U-Net Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # Decoder\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "        \n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = transforms.functional.resize(x, size=skip_connection.shape[2:])\n",
    "            \n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "        \n",
    "        return self.final_conv(x)\n",
    "\n",
    "# Initialize model\n",
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "print(f\"Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Class and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroplasticsDataset(Dataset):\n",
    "    \"\"\"Dataset class for Microplastics SEM images with segmentation masks\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir=None, transform=None, image_size=(256, 256)):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # Find all images\n",
    "        self.images = []\n",
    "        for ext in ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff', '*.JPG', '*.JPEG', '*.PNG', '*.TIF', '*.TIFF']:\n",
    "            self.images.extend(glob.glob(os.path.join(image_dir, ext)))\n",
    "        \n",
    "        self.images = sorted(self.images)\n",
    "        print(f\"Found {len(self.images)} images in {image_dir}\")\n",
    "        \n",
    "        # Verify masks if provided\n",
    "        if mask_dir and os.path.exists(mask_dir):\n",
    "            masks = []\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png', '*.tif', '*.tiff', '*.JPG', '*.JPEG', '*.PNG', '*.TIF', '*.TIFF']:\n",
    "                masks.extend(glob.glob(os.path.join(mask_dir, ext)))\n",
    "            print(f\"Found {len(masks)} masks in {mask_dir}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.images[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {img_path}\")\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load corresponding mask\n",
    "        mask = None\n",
    "        if self.mask_dir and os.path.exists(self.mask_dir):\n",
    "            # Try same filename in mask directory\n",
    "            img_name = os.path.basename(img_path)\n",
    "            mask_path = os.path.join(self.mask_dir, img_name)\n",
    "            \n",
    "            # Try different extensions if exact match not found\n",
    "            if not os.path.exists(mask_path):\n",
    "                base_name = os.path.splitext(img_name)[0]\n",
    "                for ext in ['.png', '.jpg', '.tif', '.tiff', '.PNG', '.JPG', '.TIF', '.TIFF']:\n",
    "                    mask_path = os.path.join(self.mask_dir, base_name + ext)\n",
    "                    if os.path.exists(mask_path):\n",
    "                        break\n",
    "            \n",
    "            if os.path.exists(mask_path):\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if mask is not None:\n",
    "                    # Binarize mask (threshold at 127 or any non-zero value)\n",
    "                    mask = (mask > 127).astype(np.float32)\n",
    "        \n",
    "        # Create dummy mask if no mask found\n",
    "        if mask is None:\n",
    "            mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.float32)\n",
    "        \n",
    "        # Resize to target size\n",
    "        image = cv2.resize(image, self.image_size)\n",
    "        mask = cv2.resize(mask, self.image_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Apply transforms (augmentations)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "        \n",
    "        # Ensure mask has channel dimension\n",
    "        if len(mask.shape) == 2:\n",
    "            mask = torch.FloatTensor(mask).unsqueeze(0)\n",
    "        else:\n",
    "            mask = mask.unsqueeze(0)\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# Data transforms with augmentation\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=45, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create full dataset\n",
    "print(\"\\nCreating dataset...\")\n",
    "full_dataset = MicroplasticsDataset(\n",
    "    IMAGE_DIR, \n",
    "    MASK_DIR if MASK_DIR and os.path.exists(MASK_DIR) else None,\n",
    "    transform=train_transform,\n",
    "    image_size=(256, 256)\n",
    ")\n",
    "\n",
    "# Split dataset: 70% train, 20% val, 10% test\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    full_dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Apply validation transform to val and test sets\n",
    "val_dataset.dataset.transform = val_transform\n",
    "test_dataset.dataset.transform = val_transform\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Train: {len(train_dataset)} images ({len(train_dataset)/len(full_dataset)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_dataset)} images ({len(val_dataset)/len(full_dataset)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_dataset)} images ({len(test_dataset)/len(full_dataset)*100:.1f}%)\")\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"\\nData loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Data\n",
    "\n",
    "Before training, let's visualize some sample images and their masks to verify the dataset is loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images and masks\n",
    "def visualize_samples(dataloader, num_samples=4):\n",
    "    \"\"\"Display sample images with their corresponding masks\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 8))\n",
    "    \n",
    "    data_iter = iter(dataloader)\n",
    "    images, masks = next(data_iter)\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Denormalize image\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        mask = masks[i].squeeze().numpy()\n",
    "        \n",
    "        # Display image\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f'SEM Image {i+1}', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Display mask\n",
    "        axes[1, i].imshow(mask, cmap='gray')\n",
    "        axes[1, i].set_title(f'Ground Truth Mask {i+1}', fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/kaggle/working/results/sample_data.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nSample batch statistics:\")\n",
    "    print(f\"  Image batch shape: {images.shape}\")\n",
    "    print(f\"  Mask batch shape: {masks.shape}\")\n",
    "    print(f\"  Microplastic pixel ratio: {masks.mean():.4f}\")\n",
    "    print(f\"  Image value range: [{images.min():.3f}, {images.max():.3f}]\")\n",
    "    print(f\"  Mask value range: [{masks.min():.3f}, {masks.max():.3f}]\")\n",
    "\n",
    "print(\"Visualizing sample training data...\")\n",
    "visualize_samples(train_loader, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred = pred.view(-1)\n",
    "        target = target.view(-1)\n",
    "        \n",
    "        intersection = (pred * target).sum()\n",
    "        dice = (2 * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        bce_loss = self.bce(pred, target)\n",
    "        dice_loss = self.dice(pred, target)\n",
    "        return self.alpha * bce_loss + (1 - self.alpha) * dice_loss\n",
    "\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    \"\"\"Calculate comprehensive segmentation metrics\"\"\"\n",
    "    pred_binary = (torch.sigmoid(pred) > threshold).float()\n",
    "    pred_np = pred_binary.cpu().numpy().flatten().astype(int)\n",
    "    target_np = target.cpu().numpy().flatten().astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix components\n",
    "    tp = ((pred_np == 1) & (target_np == 1)).sum()\n",
    "    fp = ((pred_np == 1) & (target_np == 0)).sum()\n",
    "    tn = ((pred_np == 0) & (target_np == 0)).sum()\n",
    "    fn = ((pred_np == 0) & (target_np == 1)).sum()\n",
    "    \n",
    "    # IoU (Intersection over Union)\n",
    "    iou = jaccard_score(target_np, pred_np, zero_division=0)\n",
    "    \n",
    "    # F1 Score\n",
    "    f1 = f1_score(target_np, pred_np, zero_division=0)\n",
    "    \n",
    "    # Precision and Recall\n",
    "    precision = precision_score(target_np, pred_np, zero_division=0)\n",
    "    recall = recall_score(target_np, pred_np, zero_division=0)\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    intersection = (pred_binary * target).sum()\n",
    "    dice = (2 * intersection) / (pred_binary.sum() + target.sum() + 1e-8)\n",
    "    \n",
    "    # Pixel Accuracy\n",
    "    pixel_accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-8)\n",
    "    \n",
    "    # Specificity (True Negative Rate)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "    \n",
    "    return {\n",
    "        'iou': iou,\n",
    "        'dice': dice.item(),\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'pixel_accuracy': pixel_accuracy,\n",
    "        'specificity': specificity,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'tn': tn,\n",
    "        'fn': fn\n",
    "    }\n",
    "\n",
    "criterion = CombinedLoss(alpha=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch with comprehensive metrics\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_metrics = {\n",
    "        'iou': 0, 'dice': 0, 'f1': 0, 'precision': 0, 'recall': 0,\n",
    "        'pixel_accuracy': 0, 'specificity': 0\n",
    "    }\n",
    "    \n",
    "    for images, masks in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        metrics = calculate_metrics(outputs, masks)\n",
    "        for key in total_metrics:\n",
    "            total_metrics[key] += metrics[key]\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metrics = {key: val / len(dataloader) for key, val in total_metrics.items()}\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate for one epoch with comprehensive metrics\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_metrics = {\n",
    "        'iou': 0, 'dice': 0, 'f1': 0, 'precision': 0, 'recall': 0,\n",
    "        'pixel_accuracy': 0, 'specificity': 0\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            metrics = calculate_metrics(outputs, masks)\n",
    "            for key in total_metrics:\n",
    "                total_metrics[key] += metrics[key]\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_metrics = {key: val / len(dataloader) for key, val in total_metrics.items()}\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "# Training loop\n",
    "NUM_EPOCHS = 20\n",
    "best_val_loss = float('inf')\n",
    "best_val_iou = 0\n",
    "train_losses, val_losses = [], []\n",
    "train_metrics_history, val_metrics_history = [], []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING U-NET FOR MICROPLASTICS SEGMENTATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    train_loss, train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_metrics_history.append(train_metrics)\n",
    "    \n",
    "    val_loss, val_metrics = validate_epoch(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_metrics_history.append(val_metrics)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Print comprehensive metrics\n",
    "    print(f\"Loss        â†’ Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "    print(f\"IoU         â†’ Train: {train_metrics['iou']:.4f} | Val: {val_metrics['iou']:.4f}\")\n",
    "    print(f\"Dice        â†’ Train: {train_metrics['dice']:.4f} | Val: {val_metrics['dice']:.4f}\")\n",
    "    print(f\"F1 Score    â†’ Train: {train_metrics['f1']:.4f} | Val: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"Precision   â†’ Train: {train_metrics['precision']:.4f} | Val: {val_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall      â†’ Train: {train_metrics['recall']:.4f} | Val: {val_metrics['recall']:.4f}\")\n",
    "    print(f\"Pixel Acc   â†’ Train: {train_metrics['pixel_accuracy']:.4f} | Val: {val_metrics['pixel_accuracy']:.4f}\")\n",
    "    print(f\"Specificity â†’ Train: {train_metrics['specificity']:.4f} | Val: {val_metrics['specificity']:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    # Save best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_val_iou = val_metrics['iou']\n",
    "        torch.save(model.state_dict(), '/kaggle/working/models/best_unet_model.pth')\n",
    "        print(\"âœ“ Best model saved (based on val loss)!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"Best validation IoU: {best_val_iou:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive training curves\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Loss\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax1.plot(train_losses, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax1.plot(val_losses, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax1.set_title('Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch', fontsize=11)\n",
    "ax1.set_ylabel('Loss', fontsize=11)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "train_ious = [m['iou'] for m in train_metrics_history]\n",
    "val_ious = [m['iou'] for m in val_metrics_history]\n",
    "ax2.plot(train_ious, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax2.plot(val_ious, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax2.set_title('IoU (Intersection over Union)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch', fontsize=11)\n",
    "ax2.set_ylabel('IoU', fontsize=11)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Dice Coefficient\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "train_dice = [m['dice'] for m in train_metrics_history]\n",
    "val_dice = [m['dice'] for m in val_metrics_history]\n",
    "ax3.plot(train_dice, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax3.plot(val_dice, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax3.set_title('Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Epoch', fontsize=11)\n",
    "ax3.set_ylabel('Dice', fontsize=11)\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "train_f1 = [m['f1'] for m in train_metrics_history]\n",
    "val_f1 = [m['f1'] for m in val_metrics_history]\n",
    "ax4.plot(train_f1, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax4.plot(val_f1, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax4.set_title('F1 Score', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Epoch', fontsize=11)\n",
    "ax4.set_ylabel('F1 Score', fontsize=11)\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "train_prec = [m['precision'] for m in train_metrics_history]\n",
    "val_prec = [m['precision'] for m in val_metrics_history]\n",
    "ax5.plot(train_prec, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax5.plot(val_prec, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax5.set_title('Precision', fontsize=14, fontweight='bold')\n",
    "ax5.set_xlabel('Epoch', fontsize=11)\n",
    "ax5.set_ylabel('Precision', fontsize=11)\n",
    "ax5.legend(fontsize=10)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "train_rec = [m['recall'] for m in train_metrics_history]\n",
    "val_rec = [m['recall'] for m in val_metrics_history]\n",
    "ax6.plot(train_rec, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax6.plot(val_rec, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax6.set_title('Recall (Sensitivity)', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Epoch', fontsize=11)\n",
    "ax6.set_ylabel('Recall', fontsize=11)\n",
    "ax6.legend(fontsize=10)\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Pixel Accuracy\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "train_acc = [m['pixel_accuracy'] for m in train_metrics_history]\n",
    "val_acc = [m['pixel_accuracy'] for m in val_metrics_history]\n",
    "ax7.plot(train_acc, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax7.plot(val_acc, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax7.set_title('Pixel Accuracy', fontsize=14, fontweight='bold')\n",
    "ax7.set_xlabel('Epoch', fontsize=11)\n",
    "ax7.set_ylabel('Accuracy', fontsize=11)\n",
    "ax7.legend(fontsize=10)\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# Specificity\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "train_spec = [m['specificity'] for m in train_metrics_history]\n",
    "val_spec = [m['specificity'] for m in val_metrics_history]\n",
    "ax8.plot(train_spec, label='Train', linewidth=2, color='#2E86C1')\n",
    "ax8.plot(val_spec, label='Validation', linewidth=2, color='#E74C3C')\n",
    "ax8.set_title('Specificity', fontsize=14, fontweight='bold')\n",
    "ax8.set_xlabel('Epoch', fontsize=11)\n",
    "ax8.set_ylabel('Specificity', fontsize=11)\n",
    "ax8.legend(fontsize=10)\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "# Summary Statistics Table\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "ax9.axis('off')\n",
    "final_train = train_metrics_history[-1]\n",
    "final_val = val_metrics_history[-1]\n",
    "table_data = [\n",
    "    ['Metric', 'Train', 'Val'],\n",
    "    ['Loss', f\"{train_losses[-1]:.4f}\", f\"{val_losses[-1]:.4f}\"],\n",
    "    ['IoU', f\"{final_train['iou']:.4f}\", f\"{final_val['iou']:.4f}\"],\n",
    "    ['Dice', f\"{final_train['dice']:.4f}\", f\"{final_val['dice']:.4f}\"],\n",
    "    ['F1', f\"{final_train['f1']:.4f}\", f\"{final_val['f1']:.4f}\"],\n",
    "    ['Precision', f\"{final_train['precision']:.4f}\", f\"{final_val['precision']:.4f}\"],\n",
    "    ['Recall', f\"{final_train['recall']:.4f}\", f\"{final_val['recall']:.4f}\"],\n",
    "    ['Pixel Acc', f\"{final_train['pixel_accuracy']:.4f}\", f\"{final_val['pixel_accuracy']:.4f}\"],\n",
    "]\n",
    "table = ax9.table(cellText=table_data, cellLoc='center', loc='center',\n",
    "                  colWidths=[0.4, 0.3, 0.3],\n",
    "                  colColours=['#3498DB']*3,\n",
    "                  cellColours=[['#ECF0F1']*3]*len(table_data))\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2)\n",
    "for i in range(len(table_data)):\n",
    "    if i == 0:\n",
    "        for j in range(3):\n",
    "            table[(i, j)].set_text_props(weight='bold', color='white')\n",
    "ax9.set_title('Final Epoch Metrics', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.suptitle('Microplastics Segmentation - Training Metrics', fontsize=18, fontweight='bold', y=0.995)\n",
    "plt.savefig('/kaggle/working/results/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Training curves saved to: /kaggle/working/results/training_curves.png\")"
   ]
    "\n",
    "# Visualize predictions with comprehensive analysis\n",
    "def visualize_predictions(model, dataloader, num_samples=6):\n",
    "    \"\"\"Visualize predictions with probability maps and overlays\"\"\"\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 5, figsize=(25, num_samples*4))\n",
    "    \n",
    "    data_iter = iter(dataloader)\n",
    "    images, masks = next(data_iter)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        predictions_prob = torch.sigmoid(outputs).cpu()\n",
    "        predictions_binary = (predictions_prob > 0.5).float()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Denormalize image\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        mask_gt = masks[i].squeeze().numpy()\n",
    "        pred_prob = predictions_prob[i].squeeze().numpy()\n",
    "        pred_binary = predictions_binary[i].squeeze().numpy()\n",
    "        \n",
    "        # Calculate metrics for this sample\n",
    "        iou = jaccard_score(mask_gt.flatten(), pred_binary.flatten(), zero_division=0)\n",
    "        dice = 2 * (mask_gt * pred_binary).sum() / (mask_gt.sum() + pred_binary.sum() + 1e-8)\n",
    "        \n",
    "        # Original Image\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title(f'Original SEM Image {i+1}', fontsize=12, fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground Truth\n",
    "        axes[i, 1].imshow(mask_gt, cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth Mask', fontsize=12, fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Prediction Probability Heatmap\n",
    "        im = axes[i, 2].imshow(pred_prob, cmap='hot', vmin=0, vmax=1)\n",
    "        axes[i, 2].set_title('Prediction Probability', fontsize=12, fontweight='bold')\n",
    "        axes[i, 2].axis('off')\n",
    "        plt.colorbar(im, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Binary Prediction\n",
    "        axes[i, 3].imshow(pred_binary, cmap='gray')\n",
    "        axes[i, 3].set_title(f'Binary Prediction\\nIoU: {iou:.3f} | Dice: {dice:.3f}', \n",
    "                            fontsize=12, fontweight='bold')\n",
    "        axes[i, 3].axis('off')\n",
    "        \n",
    "        # Overlay Comparison\n",
    "        overlay = img.copy()\n",
    "        # Green for True Positive, Red for False Positive, Blue for False Negative\n",
    "        tp_mask = (mask_gt == 1) & (pred_binary == 1)\n",
    "        fp_mask = (mask_gt == 0) & (pred_binary == 1)\n",
    "        fn_mask = (mask_gt == 1) & (pred_binary == 0)\n",
    "        \n",
    "        overlay_colored = np.zeros((*img.shape[:2], 3))\n",
    "        overlay_colored[tp_mask] = [0, 1, 0]  # Green - Correct detection\n",
    "        overlay_colored[fp_mask] = [1, 0, 0]  # Red - False positive\n",
    "        overlay_colored[fn_mask] = [0, 0, 1]  # Blue - Missed detection\n",
    "        \n",
    "        axes[i, 4].imshow(img)\n",
    "        axes[i, 4].imshow(overlay_colored, alpha=0.5)\n",
    "        axes[i, 4].set_title('Overlay\\nðŸŸ¢ TP  ðŸ”´ FP  ðŸ”µ FN', fontsize=12, fontweight='bold')\n",
    "        axes[i, 4].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/kaggle/working/results/predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Predictions saved to: /kaggle/working/results/predictions.png\")\n",
    "\n",
    "print(\"Generating prediction visualizations...\")\n",
    "visualize_predictions(model, val_loader, num_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Final Results and Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('/kaggle/working/models/best_unet_model.pth'))\n",
    "\n",
    "# Final evaluation on test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loss, test_metrics = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "# Generate comprehensive confusion matrix data\n",
    "print(\"\\nGenerating detailed metrics and confusion matrix...\")\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        all_preds.append(preds.cpu().numpy().flatten())\n",
    "        all_targets.append(masks.cpu().numpy().flatten())\n",
    "\n",
    "all_preds = np.concatenate(all_preds).astype(int)\n",
    "all_targets = np.concatenate(all_targets).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL TEST RESULTS - MICROPLASTICS SEM DATASET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š Overall Metrics:\")\n",
    "print(f\"  Loss:              {test_loss:.4f}\")\n",
    "print(f\"  IoU:               {test_metrics['iou']:.4f}\")\n",
    "print(f\"  Dice Coefficient:  {test_metrics['dice']:.4f}\")\n",
    "print(f\"  F1 Score:          {test_metrics['f1']:.4f}\")\n",
    "print(f\"\\nðŸŽ¯ Classification Metrics:\")\n",
    "print(f\"  Precision:         {test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall (Sensitivity): {test_metrics['recall']:.4f}\")\n",
    "print(f\"  Specificity:       {test_metrics['specificity']:.4f}\")\n",
    "print(f\"  Pixel Accuracy:    {test_metrics['pixel_accuracy']:.4f}\")\n",
    "print(f\"\\nðŸ§® Confusion Matrix:\")\n",
    "print(f\"  True Positives:    {tp:,}\")\n",
    "print(f\"  True Negatives:    {tn:,}\")\n",
    "print(f\"  False Positives:   {fp:,}\")\n",
    "print(f\"  False Negatives:   {fn:,}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualize confusion matrix and metrics\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "cm_display = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "im = axes[0].imshow(cm_display, cmap='Blues', aspect='auto')\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_yticks([0, 1])\n",
    "axes[0].set_xticklabels(['Background', 'Microplastic'], fontsize=11)\n",
    "axes[0].set_yticklabels(['Background', 'Microplastic'], fontsize=11)\n",
    "axes[0].set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = axes[0].text(j, i, f'{cm_display[i, j]:.3f}\\n({cm[i, j]:,})',\n",
    "                          ha=\"center\", va=\"center\", color=\"white\" if cm_display[i, j] > 0.5 else \"black\",\n",
    "                          fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Metrics Bar Chart\n",
    "metrics_names = ['IoU', 'Dice', 'F1', 'Precision', 'Recall', 'Specificity', 'Pixel Acc']\n",
    "metrics_values = [\n",
    "    test_metrics['iou'], test_metrics['dice'], test_metrics['f1'],\n",
    "    test_metrics['precision'], test_metrics['recall'], \n",
    "    test_metrics['specificity'], test_metrics['pixel_accuracy']\n",
    "]\n",
    "colors = ['#3498DB', '#2ECC71', '#F39C12', '#E74C3C', '#9B59B6', '#1ABC9C', '#34495E']\n",
    "bars = axes[1].barh(metrics_names, metrics_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_xlim(0, 1)\n",
    "axes[1].set_xlabel('Score', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Test Set Metrics', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, metrics_values)):\n",
    "    axes[1].text(value + 0.02, i, f'{value:.3f}', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Performance Summary Table\n",
    "axes[2].axis('off')\n",
    "summary_data = [\n",
    "    ['Metric', 'Score'],\n",
    "    ['Dataset', 'Microplastics SEM'],\n",
    "    ['Test Samples', f'{len(test_dataset)}'],\n",
    "    ['Model', 'U-Net'],\n",
    "    ['Epochs Trained', f'{NUM_EPOCHS}'],\n",
    "    ['', ''],\n",
    "    ['IoU', f\"{test_metrics['iou']:.4f}\"],\n",
    "    ['Dice', f\"{test_metrics['dice']:.4f}\"],\n",
    "    ['F1 Score', f\"{test_metrics['f1']:.4f}\"],\n",
    "    ['Precision', f\"{test_metrics['precision']:.4f}\"],\n",
    "    ['Recall', f\"{test_metrics['recall']:.4f}\"],\n",
    "    ['Specificity', f\"{test_metrics['specificity']:.4f}\"],\n",
    "]\n",
    "table = axes[2].table(cellText=summary_data, cellLoc='left', loc='center',\n",
    "                      colWidths=[0.6, 0.4],\n",
    "                      colColours=['#3498DB', '#3498DB'],\n",
    "                      cellColours=[['#ECF0F1', '#ECF0F1']]*len(summary_data))\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Style header row\n",
    "for j in range(2):\n",
    "    table[(0, j)].set_text_props(weight='bold', color='white')\n",
    "    table[(0, j)].set_facecolor('#2E86C1')\n",
    "\n",
    "# Highlight metric rows\n",
    "for i in [6, 7, 8, 9, 10, 11]:\n",
    "    for j in range(2):\n",
    "        table[(i, j)].set_facecolor('#D5F4E6')\n",
    "\n",
    "axes[2].set_title('Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/kaggle/working/results/final_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Final metrics visualization saved to: /kaggle/working/results/final_metrics.png\")\n",
    "\n",
    "# Visualize test predictions\n",
    "print(\"\\nGenerating test predictions visualization...\")\n",
    "visualize_predictions(model, test_loader, num_samples=6)\n",
    "\n",
    "# Save final results to text file\n",
    "results_text = f\"\"\"Microplastics Segmentation - U-Net Results\n",
    "============================================\n",
    "\n",
    "Dataset Information:\n",
    "- Source: Microplastics SEM (Mendeley)\n",
    "- Total Images: {len(full_dataset)}\n",
    "- Train/Val/Test Split: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}\n",
    "\n",
    "Model Configuration:\n",
    "- Architecture: U-Net\n",
    "- Parameters: {sum(p.numel() for p in model.parameters()):,}\n",
    "- Input Size: 256x256\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "- Epochs: {NUM_EPOCHS}\n",
    "- Loss Function: Combined (BCE + Dice)\n",
    "- Optimizer: Adam (lr=1e-4)\n",
    "\n",
    "Final Test Metrics:\n",
    "-------------------\n",
    "Loss:              {test_loss:.4f}\n",
    "IoU:               {test_metrics['iou']:.4f}\n",
    "Dice Coefficient:  {test_metrics['dice']:.4f}\n",
    "F1 Score:          {test_metrics['f1']:.4f}\n",
    "Precision:         {test_metrics['precision']:.4f}\n",
    "Recall:            {test_metrics['recall']:.4f}\n",
    "Specificity:       {test_metrics['specificity']:.4f}\n",
    "Pixel Accuracy:    {test_metrics['pixel_accuracy']:.4f}\n",
    "\n",
    "Confusion Matrix:\n",
    "----------------\n",
    "True Positives:    {tp:,}\n",
    "True Negatives:    {tn:,}\n",
    "False Positives:   {fp:,}\n",
    "False Negatives:   {fn:,}\n",
    "\n",
    "Performance Analysis:\n",
    "--------------------\n",
    "- High IoU ({test_metrics['iou']:.2%}) indicates strong overlap between predictions and ground truth\n",
    "- Dice coefficient of {test_metrics['dice']:.2%} shows excellent segmentation quality\n",
    "- Precision of {test_metrics['precision']:.2%} means {test_metrics['precision']:.2%} of detected particles are correct\n",
    "- Recall of {test_metrics['recall']:.2%} means we detect {test_metrics['recall']:.2%} of actual microplastics\n",
    "- Specificity of {test_metrics['specificity']:.2%} indicates accurate background classification\n",
    "\n",
    "Training completed successfully!\n",
    "Model saved to: /kaggle/working/models/best_unet_model.pth\n",
    "\n",
    "Generated Outputs:\n",
    "-----------------\n",
    "1. training_curves.png - Comprehensive training metrics over epochs\n",
    "2. predictions.png - Sample predictions with overlays\n",
    "3. final_metrics.png - Confusion matrix and performance summary\n",
    "4. sample_data.png - Original dataset samples\n",
    "5. final_results.txt - This file\n",
    "\"\"\"\n",
    "\n",
    "with open('/kaggle/working/results/final_results.txt', 'w') as f:\n",
    "    f.write(results_text)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL OUTPUTS SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(\"âœ“ Model:              /kaggle/working/models/best_unet_model.pth\")\n",
    "print(\"âœ“ Training curves:    /kaggle/working/results/training_curves.png\")\n",
    "print(\"âœ“ Predictions:        /kaggle/working/results/predictions.png\")\n",
    "print(\"âœ“ Final metrics:      /kaggle/working/results/final_metrics.png\")\n",
    "print(\"âœ“ Sample data:        /kaggle/working/results/sample_data.png\")\n",
    "print(\"âœ“ Results summary:    /kaggle/working/results/final_results.txt\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸŽ‰ Training complete! You can download all results from the output section.\")\n",
    "print(\"\\nðŸ“Š Use these visualizations for your presentation!\")"
   ]
  }
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. How to Use This Model for Inference\n",
    "\n",
    "After training, you can use the saved model to make predictions on new SEM images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inference on a single image\n",
    "def predict_single_image(model, image_path, device, image_size=(256, 256)):\n",
    "    \"\"\"Run inference on a single image\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    original_size = image.shape[:2]\n",
    "    \n",
    "    # Resize and normalize\n",
    "    image_resized = cv2.resize(image, image_size)\n",
    "    transform = A.Compose([\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image_resized)\n",
    "    image_tensor = augmented['image'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        prediction = torch.sigmoid(output).cpu().squeeze().numpy()\n",
    "    \n",
    "    # Resize prediction back to original size\n",
    "    prediction_resized = cv2.resize(prediction, (original_size[1], original_size[0]))\n",
    "    \n",
    "    # Threshold to binary mask\n",
    "    binary_mask = (prediction_resized > 0.5).astype(np.uint8) * 255\n",
    "    \n",
    "    return image, prediction_resized, binary_mask\n",
    "\n",
    "# Example usage (commented out - uncomment to use)\n",
    "# image, pred_prob, pred_mask = predict_single_image(model, 'path/to/image.png', device)\n",
    "# \n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "# axes[0].imshow(image)\n",
    "# axes[0].set_title('Original Image')\n",
    "# axes[0].axis('off')\n",
    "# \n",
    "# axes[1].imshow(pred_prob, cmap='hot')\n",
    "# axes[1].set_title('Prediction Probability')\n",
    "# axes[1].axis('off')\n",
    "# \n",
    "# axes[2].imshow(pred_mask, cmap='gray')\n",
    "# axes[2].set_title('Binary Mask')\n",
    "# axes[2].axis('off')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "print(\"Inference function defined. Use predict_single_image() to segment new images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### What This Notebook Does:\n",
    "âœ“ Trains a U-Net model for microplastic segmentation on SEM images\n",
    "âœ“ Uses the Microplastics SEM Dataset (Mendeley) with 237 images\n",
    "âœ“ Evaluates with IoU, Dice, F1, Precision, and Recall metrics\n",
    "âœ“ Saves trained model and visualizations\n",
    "\n",
    "### Outputs:\n",
    "- **Model**: `/kaggle/working/models/best_unet_model.pth`\n",
    "- **Training curves**: `/kaggle/working/results/training_curves.png`\n",
    "- **Predictions**: `/kaggle/working/results/predictions.png`\n",
    "- **Results summary**: `/kaggle/working/results/final_results.txt`\n",
    "\n",
    "### Next Steps:\n",
    "1. **Download the model** from Kaggle output section\n",
    "2. **Try different architectures**: MultiResUNet, U-Net++, nnU-Net\n",
    "3. **Experiment with hyperparameters**: learning rate, batch size, image size\n",
    "4. **Add classification**: Classify microplastic types (fragments, beads, fibers)\n",
    "5. **Try test-time augmentation** for better predictions\n",
    "6. **Use ensemble methods** with multiple models\n",
    "\n",
    "### For Your Presentation:\n",
    "- Show the training curves (loss, IoU, Dice)\n",
    "- Display sample predictions with original image, ground truth, and prediction\n",
    "- Highlight the final test metrics\n",
    "- Discuss particle types detected (fragments, beads, fibers)\n",
    "- Mention SEM imaging advantages for microplastic detection\n",
    "\n",
    "**Good luck with your presentation! ðŸŽ‰**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}